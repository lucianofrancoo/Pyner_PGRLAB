# ğŸ“‹ Plan de Desarrollo - Pyner PGRLAB v0.3

**Ãšltima actualizaciÃ³n:** Febrero 6, 2026  
**Estado:** ğŸ”„ En PlanificaciÃ³n  
**Objetivo Principal:** Mejorar generaciÃ³n de queries de bÃºsqueda usando Knowledge Base local de NCBI SRA

---

## ğŸ¯ VisiÃ³n General

El proyecto Pyner actualmente usa un LLM genÃ©rico (Qwen2.5) para generar queries NCBI con sinÃ³nimos bÃ¡sicos. **El desafÃ­o:** generar queries *especializadas* asimilando el conocimiento de **1.3 millones de archivos XML** del NCBI SRA local.

**SoluciÃ³n propuesta:** Extraer, estructurar y usar esa metainformaciÃ³n para crear un modelo contextualizado que entienda:
- Organismos reales estudiados en SRA
- Estrategias de secuenciaciÃ³n existentes
- Atributos de muestras (tejidos, tratamientos, etc.)
- Palabras clave del dominio bioinformÃ¡tico

**Resultado esperado:** Queries 3-5x mÃ¡s precisas â†’ Menos resultados irrelevantes â†’ AnÃ¡lisis mÃ¡s rÃ¡pido

---

## ğŸ“Š Magnitud de los Datos

```
Total de archivos:    1,340,469 archivos XML
Estructura:          
  â”œâ”€â”€ 445,489 Ã— experiment.xml  (tÃ­tulos, estrategias, librerÃ­as)
  â”œâ”€â”€ 445,489 Ã— sample.xml      (organismos, atributos)
  â””â”€â”€ 445,489 Ã— run.xml         (metadatos de ejecuciÃ³n)

Primeros 5 directorios analizados:
  DRA000001 - DRA000008 âœ… (archivo binario de estructura confirmada)
```

---

## ğŸš€ Plan de Desarrollo - 3 Fases

### â­ FASE 1: ExtracciÃ³n de Knowledge Base (KB)
**DuraciÃ³n:** 1-2 semanas  
**Responsable:** Principal developer  
**Status:** ğŸŸ¡ Por comenzar

#### Objetivo
Procesar primeros ~100k-500k archivos para extraer:
- Organismos Ãºnicos y frecuencia
- Estrategias de secuenciaciÃ³n (LIBRARY_STRATEGY)
- Fuentes de biblioteca (LIBRARY_SOURCE)
- Selecciones de biblioteca (LIBRARY_SELECTION)
- Tipos de tejido/muestra (SAMPLE_ATTRIBUTES)
- Palabras clave de tÃ­tulos y descripciones

#### Salida Esperada
```json
{
  "organisms": {
    "arabidopsis_thaliana": {
      "freq": 12453,
      "aliases": ["arabidopsis", "Arabidopsis thaliana", "ath"],
      "synonyms": ["small cress", "mouse-ear cress"]
    },
    "solanum_lycopersicum": {...}
  },
  
  "strategies": {
    "RNA-Seq": {
      "freq": 89234,
      "aliases": ["transcriptomics", "transcript-seq", "whole transcriptome"],
      "related_keywords": ["expression", "transcription", "rna"]
    },
    "WGS": {...},
    "AMPLICON": {...}
  },
  
  "treatments_and_conditions": {
    "drought": {
      "freq": 5234,
      "variants": ["water stress", "water deficit", "dehydration", "desiccation"],
      "organism_specific": {
        "arabidopsis": ["drought", "water stress"],
        "rice": ["drought", "water deficit"]
      }
    },
    "nitrogen": {...},
    "temperature": {...}
  },
  
  "tissue_types": {
    "leaf": {"freq": 34521, "aliases": ["leaves", "foliage"]},
    "root": {"freq": 28901, "aliases": ["roots", "rhizome"]},
    ...
  }
}
```

#### Tareas EspecÃ­ficas

**1.1 Crear parser XML robusto**
```python
# Script: extract_metadata.py
- Manejar 100k archivos en paralelo
- Error handling para XMLs corrompidos
- Extraer con regex/xpath campos especÃ­ficos
- Normalizar nombres (minÃºsculas, espacios)
- Contar frecuencias
```

**1.2 Procesar sample.xml**
```python
# InformaciÃ³n crÃ­tica:
- TAXON_ID â†’ SCIENTIFIC_NAME (mapping)
- SAMPLE_ATTRIBUTES â†’ extraer valores de tags
- Buscar patrones: tejido, tratamiento, tiempo, genotipo
- Crear Ã­ndice invertido (tag â†’ lista de valores Ãºnicos)
```

**1.3 Procesar experiment.xml**
```python
# InformaciÃ³n crÃ­tica:
- TITLE â†’ tokenizar y extraer conceptos
- LIBRARY_STRATEGY, LIBRARY_SOURCE, LIBRARY_SELECTION
- LIBRARY_CONSTRUCTION_PROTOCOL â†’ palabras clave importantes
```

**1.4 Crear Ã­ndice invertido global**
```python
# Para cada concepto (ej: "drought"):
- Variantes encontradas en SRA
- Frecuencia en cada organismo
- Campos donde aparece (tÃ­tulo, atributo, etc.)
- Contexto (Â¿junto con quÃ© se menciona?)
```

#### Checkpoint 1
- [ ] Parser XML funcional probado en 1000 archivos
- [ ] Ãndice invertido inicial (100k archivos)
- [ ] JSON de KB exportado
- [ ] EstadÃ­sticas principales reportadas

---

### ğŸ¤– FASE 2: Entrenamiento de Modelo Contextualizado
**DuraciÃ³n:** 2-3 semanas  
**Responsable:** ML engineer / Bioinformatician  
**Status:** ğŸ”´ Bloqueado por Fase 1

#### Objetivo
Desarrollar modelo que entienda contextos biolÃ³gicos y traduzca queries naturales a queries NCBI Ã³ptimas.

#### Enfoque 1: Basado en Reglas + KB (DeterminÃ­stico) â­â­â­
```python
# RECOMENDADO: RÃ¡pido, reproducible, no requiere GPU

class QueryOptimizer:
    def __init__(self, kb):
        self.kb = kb  # Knowledge base de Fase 1
    
    def generate_query(self, user_input):
        """
        "arabidopsis drought" â†’ 
        arabidopsis[Organism] AND 
        (drought OR "water stress" OR "water deficit"[All Fields])
        """
        # 1. Parsear input
        tokens = tokenize(user_input)
        
        # 2. Normalizar contra KB
        normalized = []
        for token in tokens:
            if token in kb["organisms"]:
                normalized.append(("organism", token, kb["organisms"][token]))
            elif token in kb["treatments"]:
                normalized.append(("treatment", token, kb["treatments"][token]))
            # ...
        
        # 3. Construir query booleana
        query_parts = []
        for type_, term, data in normalized:
            if type_ == "organism":
                query_parts.append(f"{data['scientific_name']}[Organism]")
            elif type_ == "treatment":
                variants = " OR ".join(f'"{v}"' for v in data["variants"])
                query_parts.append(f"({variants}[All Fields])")
        
        return " AND ".join(query_parts)
```

#### Enfoque 2: Fine-tune del LLM (Opcional, despuÃ©s)
```python
# Para futuro: si queremos usar LLM local + KB

# Training data:
# Input: "arabidopsis drought"
# Output: "arabidopsis[Organism] AND (drought OR \"water stress\"...)"

# Con ejemplos reales de SRA, el LLM aprenderÃ¡ mejor
```

#### Tareas EspecÃ­ficas

**2.1 Implementar Query Builder determinÃ­stico**
```python
# Script: query_optimizer.py
- Mapeo: token user input â†’ campos NCBI especÃ­ficos
- Manejo de ambigÃ¼edades (ej: "rice" = mÃºltiples especies)
- Expansion de sinÃ³nimos automÃ¡tica basada en KB
- Testing contra ejemplos conocidos
```

**2.2 Crear test suite**
```python
# Test cases:
- "arabidopsis drought" â†’ debe expandirse correctamente
- "Solanum lycopersicum nitrogen" â†’ mapear a campos existentes
- "human cancer transcriptomics" â†’ detectar que es incompatible con SRA
- Casos edge: abreviaturas, typos, tÃ©rminos raros
```

**2.3 IntegraciÃ³n con Pyner_search_v0.1.py**
```python
# Reemplazar LLM genÃ©rico con QueryOptimizer

# Antes:
- LLM genÃ©rico genera query genÃ©rica

# DespuÃ©s:
- QueryOptimizer usa KB local
- MÃ¡s preciso, mÃ¡s rÃ¡pido, sin dependencias de LLM
```

#### Checkpoint 2
- [ ] QueryOptimizer implementado
- [ ] Test suite con 50+ casos
- [ ] Resultados 3-5x mÃ¡s precisos que baseline
- [ ] DocumentaciÃ³n de campos NCBI soportados

---

### ğŸ“ˆ FASE 3: Fine-tuning y OptimizaciÃ³n
**DuraciÃ³n:** 2-4 semanas  
**Responsable:** Equipo completo (feedback loops)  
**Status:** ğŸ”´ Bloqueado por Fase 2

#### Objetivo
Validar, refinar, publicar y preparar para producciÃ³n.

#### Tareas EspecÃ­ficas

**3.1 EvaluaciÃ³n exhaustiva**
```python
# Comparar:
- Queries antigas (LLM genÃ©rico) vs nuevas (QB + KB)
- PrecisiÃ³n: Â¿CuÃ¡ntos resultados relevantes?
- Recall: Â¿Se pierden estudios importantes?
- Velocidad de bÃºsqueda

# MÃ©tricas:
- Mean Rank de estudios relevantes
- % de "ruido" en resultados
- Tiempo de bÃºsqueda
```

**3.2 Feedback de usuarios**
```
- Ejecutar Pyner_v0.2.py con nueva query
- Validar: Â¿Son los resultados Ãºtiles?
- Ajustar KB basado en feedback
- Iterar
```

**3.3 Escalabilidad**
```python
# Procesar todos los 1.3M archivos (no solo 100k)
- ParallelizaciÃ³n mÃ¡s agresiva
- OptimizaciÃ³n de Ã­ndices
- CachÃ© distribuida
- Deploy en servidor si es necesario
```

**3.4 DocumentaciÃ³n y Release**
```
- Wiki con ejemplos de queries
- API documentation
- Casos de uso de usuario
- Release v0.3 en GitHub
```

#### Checkpoint 3
- [ ] EvaluaciÃ³n completa completada
- [ ] KB procesada al 100% (1.3M archivos)
- [ ] Release v0.3 publicado
- [ ] DocumentaciÃ³n de usuario lista

---

## ğŸ“‚ Estructura de Carpetas (Propuesta)

```
Pyner_PGRLAB/
â”œâ”€â”€ README.md                          # ExplicaciÃ³n general âœ…
â”œâ”€â”€ DEVELOPMENT_PLAN.md                # Este archivo â† TÃš ESTÃS AQUÃ
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ Pyner_search_v0.1.py           # Query builder (existente)
â”‚   â”œâ”€â”€ Pyner_v0.1.py                  # BÃºsqueda simple (existente)
â”‚   â”œâ”€â”€ Pyner_v0.2.py                  # BÃºsqueda avanzada (existente)
â”‚   â”‚
â”‚   â”œâ”€â”€ extract_metadata.py            # ğŸ†• FASE 1: Parser XML
â”‚   â”œâ”€â”€ build_kb.py                    # ğŸ†• FASE 1: Construir Knowledge Base
â”‚   â”œâ”€â”€ query_optimizer.py             # ğŸ†• FASE 2: Query Builder determinÃ­stico
â”‚   â””â”€â”€ evaluate_queries.py            # ğŸ†• FASE 3: EvaluaciÃ³n de queries
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ kb/
â”‚   â”‚   â”œâ”€â”€ organisms_index.json       # ğŸ†• Output de Fase 1
â”‚   â”‚   â”œâ”€â”€ strategies_index.json      # ğŸ†•
â”‚   â”‚   â”œâ”€â”€ treatments_index.json      # ğŸ†•
â”‚   â”‚   â”œâ”€â”€ tissues_index.json         # ğŸ†•
â”‚   â”‚   â””â”€â”€ global_index.json          # ğŸ†• Ãndice invertido completo
â”‚   â”‚
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ baseline_queries.csv       # Queries antiguas (para comparaciÃ³n)
â”‚       â””â”€â”€ optimized_queries.csv      # Queries nuevas
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_extract_metadata.py       # Tests parser XML
â”‚   â”œâ”€â”€ test_query_optimizer.py        # Tests query builder
â”‚   â””â”€â”€ test_cases.json                # Casos de prueba
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ API.md                         # ğŸ†• DocumentaciÃ³n de QueryOptimizer
    â”œâ”€â”€ KB_SCHEMA.md                   # ğŸ†• Esquema del Knowledge Base
    â””â”€â”€ CONTRIBUTING.md                # ğŸ†• GuÃ­a para contribuyentes
```

---

## ğŸ‘¥ Roles y Responsabilidades

| Rol | Tareas | Requisitos |
|-----|--------|-----------|
| **Principal Dev** | Fase 1 (Parser XML) | Python, XML/XPath, paralelizaciÃ³n |
| **ML Engineer** | Fase 2 (Query Optimizer) | LÃ³gica de bÃºsqueda booleana, algo bioinformatica |
| **QA** | Fase 3 (Testing) | Casos de prueba, evaluaciÃ³n |
| **DevOps** (opcional) | Infraestructura | Docker, servidor (si escalamos) |

---

## ğŸ“… Timeline Estimado

```
FASE 1 (ExtracciÃ³n KB)
â”œâ”€ Semana 1:  Parser XML + tests bÃ¡sicos
â”œâ”€ Semana 2:  Procesar 100k archivos + validar Ã­ndice
â””â”€ Semana 2:  OptimizaciÃ³n de rendimiento
                âœ… KB inicial completado

FASE 2 (Query Optimizer)
â”œâ”€ Semana 3:  Query Builder v1
â”œâ”€ Semana 4:  Integration + test suite (50+ casos)
â””â”€ Semana 4:  ValidaciÃ³n contra baseline LLM
                âœ… QueryOptimizer productivo

FASE 3 (Refinamiento)
â”œâ”€ Semana 5-6: Scalability (todos los 1.3M archivos)
â”œâ”€ Semana 6-7: EvaluaciÃ³n exhaustiva + feedback
â””â”€ Semana 8:   Release v0.3 + DocumentaciÃ³n
                âœ… Release publico

TOTAL: ~8 semanas (2 meses)
Con parallelizaciÃ³n: PodrÃ­a reducirse a 4-6 semanas
```

---

## ğŸ“ CÃ³mo Contribuir

### Para Contribuyentes que quieren participar:

**FASE 1 - ExtracciÃ³n KB**
```bash
# Si quieres ayudar:
1. Fork el proyecto
2. Crea rama: git checkout -b feature/extract-metadata
3. Implementa parser para un tipo de XML (sample.xml, experiment.xml)
4. Tests unitarios incluidos
5. Pull request a main con descripciÃ³n

# Tareas disponibles:
- [ ] Parser de SAMPLE_ATTRIBUTES
- [ ] Parser de LIBRARY_DESCRIPTOR
- [ ] NormalizaciÃ³n de nombres de organismos
- [ ] DeduplicaciÃ³n de sinÃ³nimos
```

**FASE 2 - Query Optimizer**
```bash
# Si tienes experiencia en bioinformatica:
1. Entender estructura de queries NCBI
2. Implementar mapeos: conceptos usuario â†’ campos NCBI
3. Testing exhaustivo
4. DocumentaciÃ³n de lÃ³gica de mapeo
```

**FASE 3 - Testing y Docs**
```bash
# Si prefieres QA/documentaciÃ³n:
1. Crear casos de prueba en test_cases.json
2. Evaluar precisiÃ³n de queries
3. Escribir documentaciÃ³n de usuario
4. Feedback y mejoras
```

### Checklist de ContribuciÃ³n
- [ ] CÃ³digo comentado y formateado (PEP8)
- [ ] Tests incluidos (mÃ­nimo 70% coverage)
- [ ] DocumentaciÃ³n clara
- [ ] Commit message descriptivo
- [ ] Referencia issues/PRs relacionados

---

## ğŸ”§ Requisitos TÃ©cnicos

### Hardware (Recomendado)
```
Para Fase 1 (procesar 1.3M archivos):
- MÃ­nimo: 16GB RAM, procesador multicore
- Ideal: 32GB RAM, GPU (opcional)

Usuario tiene ya disponible:
âœ… GPU 3x NVIDIA RTX 4000 Ada (~24GB VRAM cada una)
âœ… 251GB RAM
âœ… Procesador multicore
â†’ PERFECTO para escalar a todos los 1.3M archivos
```

### Software
```
- Python 3.8+
- BioPython (Entrez)
- Ollama (para LLM si lo usamos)
- Pandas (anÃ¡lisis)
- NumPy (operaciones)
```

### Dependencias
```bash
pip install -r requirements-dev.txt
# Includes: pytest, black, flake8 (testing/linting)
```

---

## ğŸ“Š MÃ©tricas de Ã‰xito (KPIs)

Al final de Fase 3, esperamos:

| MÃ©trica | Baseline | Target |
|---------|----------|--------|
| PrecisiÃ³n de queries | 65% | 85-90% |
| # de resultados "ruido" | -40% | -10-15% |
| Tiempo generaciÃ³n query | 3-5s (LLM) | <500ms (KB) |
| Cobertura de organismos | 10 especies | 500+ especies |
| DocumentaciÃ³n | 2 archivos | 5+ + API docs |

---

## ğŸš¨ Riesgos y MitigaciÃ³n

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|--------|-----------|
| Memory overflow (1.3M files) | Media | Alto | Procesar en chunks, usar generadores |
| XML corrompidos | Alta | Bajo | Error handling robusto + logging |
| LÃ³gica booleana incorrecta | Media | Alto | Test suite completo + validaciÃ³n |
| Performance (bÃºsqueda lenta) | Baja | Medio | IndexaciÃ³n, cachÃ©, optimizaciÃ³n |

---

## ğŸ“ Contacto y Preguntas

- **Issues:** [GitHub Issues](https://github.com/lucianofrancoo/Pyner_PGRLAB/issues)
- **Discussions:** [GitHub Discussions](https://github.com/lucianofrancoo/Pyner_PGRLAB/discussions)
- **Email:** lucianofranco.a@gmail.com

---

## ğŸ“ Cambios y Actualizaciones

| Fecha | QuiÃ©n | Cambio |
|-------|-------|--------|
| 2026-02-06 | GitHub Copilot | Plan inicial creado |
| - | - | - |

---

**Estado General:** ğŸŸ¡ Listo para Fase 1  
**Ãšltima review:** 2026-02-06  
**PrÃ³xima milestone:** Fase 1, Checkpoint 1 âœ…
