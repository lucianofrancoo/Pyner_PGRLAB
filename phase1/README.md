# ğŸ”¬ Pyner Phase 1: Knowledge Base Extraction

**Objetivo:** Extraer 1.3M de archivos XML de NCBI SRA y construir un Knowledge Base estructurado.

**Recursos Disponibles:**
- 3x NVIDIA RTX 4000 Ada (~24GB VRAM cada una)
- 251GB RAM
- Multicore CPU

---

## ğŸ“‹ Estructura

```
phase1/
â”œâ”€â”€ config.py                    â† ConfiguraciÃ³n centralizada
â”œâ”€â”€ utils.py                     â† Utilidades (logging, GPU, checkpoints)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ stage1_parse_xml.py     â† Parsear 1K archivos iniciales (prueba)
â”‚   â”œâ”€â”€ stage2_parallel_gpu.py   â† Paralelizar 50K archivos
â”‚   â””â”€â”€ stage3_parallel_gpu.py   â† Escalar a 500K archivos (mÃ¡x)
â”œâ”€â”€ checkpoints/                 â† RecuperaciÃ³n ante fallos
â”œâ”€â”€ logs/                        â† Logs detallados de ejecuciÃ³n
â”œâ”€â”€ output/                      â† Ãndices JSON generados
â””â”€â”€ tests/                       â† Fixtures para testing
```

---

## ğŸš€ EjecuciÃ³n RÃ¡pida

### Prerequisitos

```bash
# Instalar dependencias
pip install -r requirements-dev.txt

# Verificar configuraciÃ³n
cd phase1
python config.py
```

### Stage 1: Prueba Inicial (1K archivos)

```bash
cd phase1

# Ejecutar parser bÃ¡sico
python scripts/stage1_parse_xml.py

# Output esperado:
# - phase1/output/stage1_indices.json
# - phase1/logs/stage1_parse_xml_YYYYMMDD_HHMMSS.log
# 
# Tiempo esperado: ~2-5 minutos
# Resultado: Fase 1 stage 1 completada âœ…
```

**Monitor mientras se ejecuta:**
```bash
# En otra terminal
tail -f phase1/logs/stage1_parse_xml_*.log
```

### Stage 2: Paralelo GPU - 50K Archivos

```bash
cd phase1

# Ejecutar con 8 workers y 3 GPUs
python scripts/stage2_parallel_gpu.py --stage 2

# Output:
# - phase1/output/stage2_knowledge_base.json
# - phase1/checkpoints/stage2/ (recuperaciÃ³n)
#
# Tiempo esperado: ~5-10 minutos
# Throughput: ~100-150 archivos/seg
```

### Stage 3: Escalar a 500K Archivos

```bash
cd phase1

# Procesar 500K archivos (mÃ¡ximo para esta fase)
python scripts/stage2_parallel_gpu.py --stage 3

# Output:
# - phase1/output/stage3_knowledge_base.json
# - phase1/logs/stage3_parallel_*.log
#
# Tiempo esperado: ~50-100 minutos
# Sistema completo con checkpoint recovery
```

---

## ğŸ¯ Fases y Checkpoints

### Estructura de Fases

```
PHASE 1: KNOWLEDGE BASE EXTRACTION
â”‚
â”œâ”€â”€ STAGE 1: Parse XML (1K test)
â”‚   â”œâ”€â”€ âœ… Discover BioProjects
â”‚   â”œâ”€â”€ âœ… Parse experiment.xml
â”‚   â”œâ”€â”€ âœ… Parse sample.xml
â”‚   â”œâ”€â”€ âœ… Parse run.xml
â”‚   â”œâ”€â”€ âœ… Build initial indices
â”‚   â””â”€â”€ âœ… Save output JSON
â”‚
â”œâ”€â”€ STAGE 2: Parallel GPU (50K production)
â”‚   â”œâ”€â”€ âœ… Discovery (50K BioProjects)
â”‚   â”œâ”€â”€ âœ… Init 8 worker processes
â”‚   â”œâ”€â”€ âœ… Assign 3 GPUs (round-robin)
â”‚   â”œâ”€â”€ âœ… Batch distribution
â”‚   â”œâ”€â”€ âœ… Parallel processing
â”‚   â”œâ”€â”€ âœ… Aggregation
â”‚   â”œâ”€â”€ âœ… Generate complete KB
â”‚   â””â”€â”€ âœ… Checkpoint every 10K files
â”‚
â””â”€â”€ STAGE 3: Full Scale (500K production)
     â”œâ”€â”€ âœ… Same as Stage 2
     â”œâ”€â”€ âœ… Longer runtime (~1-2 hours)
     â”œâ”€â”€ âœ… Recovery from checkpoints
     â””â”€â”€ âœ… Final KB generation
```

### Checkpoint System

Si hay fallo, recuperaciÃ³n automÃ¡tica:

```bash
# Si Stage 2 falla en archivo 25000:
âŒ Timeout/Error durante procesamiento

# Ejecutar de nuevo:
python scripts/stage2_parallel_gpu.py --stage 2

# Sistema automÃ¡ticamente:
âœ… Detecta checkpoint en archive 25000
âœ… Resume desde ahÃ­
âœ… ContinÃºa procesamiento
âœ… Sin perder trabajo anterior
```

---

## ğŸ“Š Debug & Monitoring

Cada script imprime:
1. **Print de secciÃ³n** - QuÃ© estÃ¡ haciendo
2. **Print de progreso** - Cada 100 archivos
3. **Print de recursos** - RAM, CPU, GPU cada 5 segundos
4. **Print de errores** - Con contexto completo

### Ejemplo de Output:

```
======================================================================
ğŸ“ STAGE 1: XML PARSING
======================================================================
ğŸ”„ Verificando checkpoint anterior...
ğŸ“ Buscando XMLs en: /home/lahumada/disco1/NCBI_Metadata/SRA
ğŸ“Š Total de BioProjects encontrados: 445,489

ğŸ¯ Procesando primeros: 1,000 BioProjects

======================================================================
ğŸ“ PARSING: Extrayendo metadatos
======================================================================
[DEBUG] @elapsed=0.1s | XML Parsing | [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 10.0% 
        | Generated: 1,234 organisms, 45 strategies

[DEBUG] @elapsed=5.2s | XML Parsing | RAM: 4.5GB | CPU: 45.2%
        | Processed: 100/1,000 files

[DEBUG] @elapsed=10.3s | XML Parsing | [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20.0%
        | Rate: 50.3 files/sec | ETA: 3.2 min

... (cada 100 archivos)

======================================================================
âœ… STAGE 1 COMPLETADO
======================================================================
  Total Experiments:...................... 5,432
  Unique Organisms:....................... 1,234
  Unique Strategies:...................... 45
  Parse Errors:........................... 23
  Tiempo total:........................... 125.45 sec (2.09 min)
======================================================================
```

---

## ğŸ” Verificar Resultados

### Output JSON Structure:

```bash
# Ver tamaÃ±o de output
ls -lh phase1/output/

# Ejemplo:
# stage1_indices.json      ~2MB
# stage2_knowledge_base.json ~50MB
# stage3_knowledge_base.json ~500MB (final KB)

# Verificar contenido
head -100 phase1/output/stage1_indices.json | python -m json.tool

# Contar organismos Ãºnicos
python -c "
import json
data = json.load(open('phase1/output/stage1_indices.json'))
print(f'Organismos: {data[\"stats\"][\"unique_organisms\"]}')
print(f'Estrategias: {data[\"stats\"][\"unique_strategies\"]}')
"
```

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Ajustar parÃ¡metros

Editar `phase1/config.py`:

```python
# LÃ­nea ~30: Cambiar nÃºmero mÃ¡ximo de archivos
MAX_FILES_PHASE1_STAGE1 = 5000   # Aumentar a 5K para prueba mÃ¡s grande

# LÃ­nea ~35: ParalelizaciÃ³n
NUM_WORKERS = 16  # MÃ¡s workers = mÃ¡s rÃ¡pido (si hay CPU)
BATCH_SIZE = 50   # Batches mÃ¡s pequeÃ±os = mejor distribuciÃ³n

# LÃ­nea ~45: GPU
GPU_IDS = [0, 1, 2]  # Usar todas 3 GPUs
GPU_MEMORY_FRACTION = 0.9  # Usar 90% de VRAM

# LÃ­nea ~57: Checkpoint
CHECKPOINT_INTERVAL = 5000  # Checkpoint cada 5K files

# LÃ­nea ~70: Debug
DEBUG_PRINT_INTERVAL = 50  # Print cada 50 files (mÃ¡s verbose)
```

Luego ejecutar:

```bash
python scripts/stage2_parallel_gpu.py --stage 2
```

---

## ğŸ› Troubleshooting

### Problema: "GPU out of memory"

```
torch.cuda.OutOfMemoryError: CUDA out of memory

SoluciÃ³n:
1. Reducir GPU_MEMORY_FRACTION en config.py
2. Reducir BATCH_SIZE
3. Reducir NUM_WORKERS
```

### Problema: "Stuck on checkpoint"

```
â±ï¸ Worker timeout esperando trabajo

SoluciÃ³n:
1. Aumentar timeout: config.py lÃ­nea ~50
2. Reducir NUM_WORKERS
3. Killer manualmente: pkill -f stage2_parallel_gpu.py
```

### Problema: "Output JSON demasiado grande"

```
El archivo JSON es > 1GB

SoluciÃ³n:
1. Usar stage2 en lugar de stage3 (50K vs 500K)
2. Cambiar output format a parquet (mÃ¡s compactado)
3. Dividir en mÃºltiples JSONs
```

---

## ğŸ“ˆ Performance Expectations

| Stage | Files | Workers | GPUs | Time | Throughput |
|-------|-------|---------|------|------|------------|
| 1 | 1K | 1 | 0 | 2-5 min | ~200 files/sec |
| 2 | 50K | 8 | 3 | 5-10 min | ~100-150 files/sec |
| 3 | 500K | 8 | 3 |50-100 min | ~80-150 files/sec |

Con 3x RTX 4000 Ada y 8 workers, esperamos **~100-150 files/sec**.

---

## ğŸ“ Output Knowledge Base (KB)

DespuÃ©s de cualquier stage, habrÃ¡ JSON con estructura:

```json
{
  "stage": 1,
  "timestamp": "2026-02-06T14:30:00",
  "files_processed": 1000,
  "statistics": {
    "total_experiments": 5432,
    "unique_organisms": 1234,
    "unique_strategies": 45
  },
  "organisms": {
    "arabidopsis_thaliana": {"count": 234, "studies": 145},
    "solanum_lycopersicum": {"count": 89, "studies": 54}
  },
  "strategies": {
    "RNA-Seq": 2345,
    "WGS": 1234
  }
}
```

---

## âœ… Checklist de ValidaciÃ³n

- [ ] `python config.py` ejecuta sin errores
- [ ] Logs se generan en `phase1/logs/`
- [ ] Checkpoints se crean en `phase1/checkpoints/` cada 10K archivos
- [ ] Output JSON generado en `phase1/output/`
- [ ] JSON es vÃ¡lido (no corrupto)
- [ ] GPU memory se libera despuÃ©s de terminar
- [ ] RecuperaciÃ³n automÃ¡tica funciona si se interrumpe

---

## ğŸ“ Debug

Si algo va mal:

```bash
# 1. Ver Ãºltimo log
tail -50 phase1/logs/*.log

# 2. Ver checkpoints disponibles
ls -la phase1/checkpoints/stage2/

# 3. Ver output generado
ls -lh phase1/output/

# 4. Validar JSON
python -m json.tool phase1/output/stage1_indices.json > /dev/null

# 5. Ver estadÃ­sticas en tiempo real
watch -n 1 'ls -la phase1/logs/stage2_parallel_*.log | tail -1'
```

---

**Â¡Listo para ejecutar! ğŸš€** 

Comienza con Stage 1 para validar setup:
```bash
cd phase1
python scripts/stage1_parse_xml.py
```
